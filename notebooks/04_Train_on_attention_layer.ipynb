{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01487b7-f733-44ff-8be8-42b70b1a7f04",
   "metadata": {},
   "source": [
    "# **Third experiment: training a XGBoost probe on attention layer**\n",
    "\n",
    "We have trained a probe on the best-performing activation layer and achieved encouraging, though not fully satisfactory, results. Subsequently, we attempted training on multiple activation layers but quickly observed diminishing returns.\n",
    "\n",
    "In this notebook, we explore a different approach: training a probe on layer 16's *attention* components (the most expressive layer, as established by our earlier experiments). We investigate two distinct strategies:\n",
    "\n",
    "- Using the output of the multi-head attention block (attention layer) rather than the output of the feed-forward network (activation layer);\n",
    "- Using a statistical summary of the same attention layer, which may capture dynamics and other fine-grained properties.\n",
    "\n",
    "We then experiment with hybrid approaches (concatenating attention statistics and MHA outputs with hidden states) and evaluate the effect of retaining varying percentages of the most informative features.\n",
    "\n",
    "### 1. Installing required libraries\n",
    "\n",
    "So, let's first install the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b92b46-5f79-4eb0-bdd8-3703c53311d5",
   "metadata": {
    "id": "f6b92b46-5f79-4eb0-bdd8-3703c53311d5",
    "outputId": "1b51c12d-b493-4132-a668-3069312042f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/julienbrasseur/llm-hallucination-detector.git\n",
      "  Cloning https://github.com/julienbrasseur/llm-hallucination-detector.git to /tmp/pip-req-build-l64dy7_y\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/julienbrasseur/llm-hallucination-detector.git /tmp/pip-req-build-l64dy7_y\n",
      "  Resolved https://github.com/julienbrasseur/llm-hallucination-detector.git to commit 77b721d351f3cb5b08d8447d199d6afe38970d26\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llmscan==0.1.0) (2.4.1+cu124)\n",
      "Collecting transformers>=4.36.0 (from llmscan==0.1.0)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting xgboost>=2.0.0 (from llmscan==0.1.0)\n",
      "  Downloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting scikit-learn>=1.3.0 (from llmscan==0.1.0)\n",
      "  Downloading scikit_learn-1.8.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from llmscan==0.1.0) (1.26.3)\n",
      "Collecting scipy>=1.11.0 (from llmscan==0.1.0)\n",
      "  Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting tqdm>=4.65.0 (from llmscan==0.1.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting accelerate>=0.25.0 (from llmscan==0.1.0)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting matplotlib>=3.7.0 (from llmscan==0.1.0)\n",
      "  Downloading matplotlib-3.10.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.25.0->llmscan==0.1.0) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.25.0->llmscan==0.1.0) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.25.0->llmscan==0.1.0) (6.0.2)\n",
      "Collecting huggingface_hub>=0.21.0 (from accelerate>=0.25.0->llmscan==0.1.0)\n",
      "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.25.0->llmscan==0.1.0)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (2024.2.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (0.27.2)\n",
      "Collecting shellingham (from huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0)\n",
      "  Downloading typer_slim-0.20.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (4.9.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (4.6.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0) (0.14.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->llmscan==0.1.0)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.7.0->llmscan==0.1.0)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.0->llmscan==0.1.0)\n",
      "  Downloading fonttools-4.61.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.7.0->llmscan==0.1.0)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llmscan==0.1.0) (10.2.0)\n",
      "Collecting pyparsing>=3 (from matplotlib>=3.7.0->llmscan==0.1.0)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llmscan==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llmscan==0.1.0) (1.16.0)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn>=1.3.0->llmscan==0.1.0)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn>=1.3.0->llmscan==0.1.0)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->llmscan==0.1.0) (3.0.0)\n",
      "Collecting huggingface_hub>=0.21.0 (from accelerate>=0.25.0->llmscan==0.1.0)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.36.0->llmscan==0.1.0)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->llmscan==0.1.0) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.36.0->llmscan==0.1.0)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->llmscan==0.1.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.36.0->llmscan==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.36.0->llmscan==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->llmscan==0.1.0) (1.3.0)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface_hub>=0.21.0->accelerate>=0.25.0->llmscan==0.1.0)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading scikit_learn-1.8.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m135.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m166.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m203.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m184.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: llmscan\n",
      "  Building wheel for llmscan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llmscan: filename=llmscan-0.1.0-py3-none-any.whl size=18859 sha256=8a48cbdd790f4c5434bd332f0c1f9bc6035ae2cb5f2365cf54568878ee2eaf1e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-u7_sxe95/wheels/eb/e6/51/577f098f1ff2729ce5349f16e3327eba87b9c2b9d3ea4df270\n",
      "Successfully built llmscan\n",
      "Installing collected packages: tqdm, threadpoolctl, scipy, safetensors, regex, pyparsing, kiwisolver, joblib, hf-xet, fonttools, cycler, contourpy, xgboost, scikit-learn, matplotlib, huggingface_hub, tokenizers, transformers, accelerate, llmscan\n",
      "\u001b[2K  Attempting uninstall: pyparsing━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/20\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: pyparsing 2.4.7━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/20\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling pyparsing-2.4.7:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/20\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled pyparsing-2.4.7━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/20\u001b[0m [scipy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [llmscan]8/20\u001b[0m [accelerate]s]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 hf-xet-1.2.0 huggingface_hub-0.36.0 joblib-1.5.3 kiwisolver-1.4.9 llmscan-0.1.0 matplotlib-3.10.8 pyparsing-3.2.5 regex-2025.11.3 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.16.3 threadpoolctl-3.6.0 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.3 xgboost-3.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets\n",
      "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.3)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.6.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-4.4.2-py3-none-any.whl (512 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.18-py311-none-any.whl (144 kB)\n",
      "Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n",
      "Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m160.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, frozenlist, dill, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [datasets]/15\u001b[0m [datasets]ess]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 datasets-4.4.2 dill-0.4.0 frozenlist-1.8.0 multidict-6.7.0 multiprocess-0.70.18 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 pytz-2025.2 tzdata-2025.3 xxhash-3.6.0 yarl-1.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install `llmscan`\n",
    "!pip install git+https://github.com/julienbrasseur/llm-hallucination-detector.git\n",
    "\n",
    "# Install `datasets`\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b3029-5dbb-457a-a1e8-858495aab50b",
   "metadata": {
    "id": "039b3029-5dbb-457a-a1e8-858495aab50b"
   },
   "source": [
    "### 2. Data preparation\n",
    "\n",
    "Now, as before, we load the dataset from Hugging Face and convert it to a standard OpenAI conversation format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbcbf0e-27c4-48d7-a9be-78c0de37c688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469,
     "referenced_widgets": [
      "a82dc08c07c948d5a5052cd5045121e8",
      "79c5ec9874134743b378f9e853ce7a28",
      "f4c1e92080cb4d86b7d85b39f4f228fe",
      "ed5c579bab0f445bbad1fe66597d5dfc",
      "10b74c33e72240448d47544635a144bb",
      "36f5b44b9f5348f49f06237f7cb76b04",
      "2de6eda7d4d24143b31286f88c26a1ec",
      "caa75872b0d64351a72afe3085672a15",
      "8e4cf79bf89c479f8b57dd4d77dc1e0c",
      "de15348757074e3eae0b2a239316e378",
      "a16b45ebe55047d29366829487cb0708",
      "34b95ce1a9574f07b932d4881a10c092",
      "d683148619be493da43c6b0f41a356ab",
      "ec190b154d6c4d318190846bf09f6967",
      "ceccb80ddc0d4cf39bb6a25ec241111d",
      "eef41e96476f4b0bad7006b343db7d90",
      "8f1c5006c2564151a289266dcbf53c72",
      "4133921f995f4cc58da4698148864024",
      "ed1806338c344271be3a0eeecf67c319",
      "38bfaf26ea624a0fab7ef5b963e714b7",
      "d8f6a863ec20497586e077b694b9e78a",
      "4373fab6488b438c8ac71a4df9135a5f",
      "ecf05abeb8914aba820fcf25e37682d0",
      "1e296dd4ba2d47038b537ce23ce1e2d6",
      "1f3748df983d4cde9106b37a9d96c635",
      "aeb7e90c064e49c4bb2f2a14a84b59fe",
      "78091de8c9ff498db284b55a7fe5fe71",
      "5f60bc4dd0aa4f91a93894ac0b097081",
      "e66917517e8744acbddff69977fabc80",
      "1e357cf6c2704d78845824c672480807",
      "d6bfd3ea72ae4d989b8e09f895d24d27",
      "ed0097519ece44409defee81c285d1b8",
      "1bbb40ba5bc84a6aba4d713dfea879c2",
      "ce90834f883446718455b635a58d1a73",
      "2221751de794442f96a67ffab42600d7",
      "0acab963daac41db9bd9779a7098b084",
      "aa056af3805642fb8af20ba9c9429b46",
      "4ec26ff17e574164a46e1aa60461400e",
      "7be8dff60be34777acee415b27750355",
      "52d51718570d42d7a9e354a7419e02da",
      "d3a7d585a68f4e1aa8277a12647b25e3",
      "83cc4ed651274e27b9015386c2b4d0dd",
      "a540eba5921c4af5b984bbdf70833724",
      "9674ecbcaff548e3810864b953199776",
      "aff3c0dab3014c40871e3b8746e4e2c6",
      "0452669fae8242b298b8d880028098b4",
      "d8cc9e95ba774ae489175535bfc4de7b",
      "f5bfe3bc46ce4e7eb3ce3126041e1e84",
      "e04a6c11769d4562b4db0b027c39fd04",
      "45ed12a939af4988a525a18ff3e2f616",
      "2419c406429345d6b664c681cf61cd9d",
      "d2825b07820f478b8bcda4a6ac82cc57",
      "2c24017b536e45aa884931a2772c765a",
      "3aca7f7a83734ceda3774b0646358cf0",
      "7782fba325214679abd9ed7a032d3adc",
      "268a5142dc4b4d49ad71ac12697d6b4b",
      "b51f9b680a254c9e9aa0142185b99187",
      "7d99075f61984ebcaac554325e70c673",
      "f18967fe7d264f59881969d0960001fc",
      "1328b0f8dc204c0e80c3eb2529f07a6a",
      "8a3d8813321941709be70726461afe0f",
      "eb1a302ddb7b42229216c7bdbbceed96",
      "948c961115ee494ba20fe80368301126",
      "c754abbfa29043708b0a2e2333396697",
      "5c0e015f35b747048ea983c33466a2e8",
      "a7eaceee911f481da589a1595495c463",
      "710b487e403947d0a194f054f615d65d",
      "0083a959621c4d708460522cee4c2f20",
      "aae39a88bd144458a391de1ebe69a948",
      "39886c30652842eba357df14b00a294c",
      "ee18ecf27739433091224048aef7d07e",
      "13b0d52645834245879187046d6fd8e4",
      "976bd147ff38479ca49b078ad4db6dca",
      "f635a6946ec54154a563d38a6c11924f",
      "36a9599d8e6048f9b2f3e833d996da15",
      "6b3b7ea3c8674fdbbdbc78c34a071956",
      "b22abc79b9dc43b3b6887a808831b2fe"
     ]
    },
    "id": "dfbcbf0e-27c4-48d7-a9be-78c0de37c688",
    "outputId": "152e2e57-8b18-4bd7-97e8-f3622e385bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: krogoldAI/hallucination-labeled-dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00c4d0618b94e778acfa546ad1ca211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/58.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e09649d728a4d539ada1c226a6c18a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/78.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd0f198417143cab2e20201913a2c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/16.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba696fd7949044919a4caac40766cf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40840821aa43481cbcc67d4dd2717457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/101618 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115d70fed2db4e659164d570fc81222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/21775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ec1ce194ef4a5595bff16c79d2f078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/21776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded and formatted:\n",
      "  Train:      101,618 examples\n",
      "  Validation: 21,775 examples\n",
      "  Test:       21,776 examples\n",
      "  Class distribution (train): 68,913 non-hallucination, 32,705 hallucination\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Set training dataset path\n",
    "DATASET_NAME = \"krogoldAI/hallucination-labeled-dataset\"\n",
    "\n",
    "def load_and_format_dataset(dataset_name: str):\n",
    "    \"\"\"\n",
    "    Load HuggingFace dataset and convert to conversation format.\n",
    "\n",
    "    This function converts dataset with 'input', 'target', 'hallucination' fields\n",
    "    to the standard conversation format expected by the pipeline.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_data, val_data, test_data, train_labels, val_labels, test_labels)\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset: {dataset_name}\")\n",
    "    ds = load_dataset(dataset_name)\n",
    "\n",
    "    # Shuffle each split\n",
    "    ds[\"train\"] = ds[\"train\"].shuffle(seed=42)\n",
    "    ds[\"validation\"] = ds[\"validation\"].shuffle(seed=42)\n",
    "    ds[\"test\"] = ds[\"test\"].shuffle(seed=42)\n",
    "\n",
    "    def format_split(split):\n",
    "        \"\"\"Convert HF dataset split to conversation format.\"\"\"\n",
    "        formatted = []\n",
    "        labels = []\n",
    "\n",
    "        for item in split:\n",
    "            # Extract fields from your HF dataset format\n",
    "            user_msg = item[\"input\"]\n",
    "            assistant_msg = item[\"target\"]\n",
    "            label = int(item[\"hallucination\"])\n",
    "\n",
    "            # Convert to standard conversation format\n",
    "            formatted.append({\n",
    "                \"conversation\": [\n",
    "                    {\"role\": \"user\", \"content\": user_msg},\n",
    "                    {\"role\": \"assistant\", \"content\": assistant_msg},\n",
    "                ]\n",
    "            })\n",
    "            labels.append(label)\n",
    "\n",
    "        return formatted, np.array(labels)\n",
    "\n",
    "    # Format all splits\n",
    "    train_data, train_labels = format_split(ds[\"train\"])\n",
    "    val_data, val_labels = format_split(ds[\"validation\"])\n",
    "    test_data, test_labels = format_split(ds[\"test\"])\n",
    "\n",
    "    print(f\"Dataset loaded and formatted:\")\n",
    "    print(f\"  Train:      {len(train_data):,} examples\")\n",
    "    print(f\"  Validation: {len(val_data):,} examples\")\n",
    "    print(f\"  Test:       {len(test_data):,} examples\")\n",
    "    print(f\"  Class distribution (train): \"\n",
    "          f\"{(train_labels == 0).sum():,} non-hallucination, \"\n",
    "          f\"{(train_labels == 1).sum():,} hallucination\")\n",
    "\n",
    "    return train_data, val_data, test_data, train_labels, val_labels, test_labels\n",
    "\n",
    "# Load and format dataset\n",
    "train_data, val_data, test_data, train_labels, val_labels, test_labels = \\\n",
    "    load_and_format_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09c88e-48a5-4605-a5c8-35a53d2f8c40",
   "metadata": {
    "id": "ab09c88e-48a5-4605-a5c8-35a53d2f8c40"
   },
   "source": [
    "### 3. Extracting attention statistics summary and MHA output for layer 16\n",
    "\n",
    "We now simultaneously extract the multi-head attention output for layer 16 along with a statistical summary of the same output. For each attention head, we compute 12 distinct metrics. The comprehensive list can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb13746-0d47-4a14-841f-be809c17f607",
   "metadata": {
    "id": "ebb13746-0d47-4a14-841f-be809c17f607",
    "outputId": "7a637b57-37dc-4a3e-9f68-b8a2b1bce2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy\n",
      "max\n",
      "std\n",
      "gini\n",
      "simpson\n",
      "effective_token_count\n",
      "skewness\n",
      "top1_mass\n",
      "top5_mass\n",
      "top10p_mass\n",
      "mean_relative_distance\n",
      "attention_to_bos\n",
      "frobenius\n",
      "head_output_norm\n",
      "attn_value_correlation\n"
     ]
    }
   ],
   "source": [
    "from llmscan import AVAILABLE_STATS\n",
    "\n",
    "# Check available statistics\n",
    "for stat in AVAILABLE_STATS:\n",
    "    print(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e5735-49d3-4ad8-b502-3f1e8e2424a8",
   "metadata": {},
   "source": [
    "Note that `head_output_norm` and `attn_value_correlation` have not yet been implemented, as they are architecture-dependent and would require non-trivial implementation effort. To assess whether this effort is warranted, we first experiment with the remaining 12 metrics.\n",
    "\n",
    "While perhaps unconventional in this context, we include `frobenius`, the standard Frobenius matrix norm (equivalent to the $\\ell^2$-norm), on a purely exploratory basis. This metric can be interpreted as the overall \"energy\" of the attention pattern across the full generation, potentially capturing whether attention patterns remain consistent across assistant tokens (i.e., attending to similar positions) or exhibit high variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5a47b-af00-4e31-9575-d6dabce37fbd",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5b299b31558b47bfa1c0916231859d27"
     ]
    },
    "id": "54f5a47b-af00-4e31-9575-d6dabce37fbd",
    "outputId": "dab02414-9854-4d4e-ecaa-35616e03d606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "  Stats to compute: ['entropy', 'max', 'std', 'gini', 'simpson', 'effective_token_count', 'skewness', 'top5_mass', 'top10p_mass', 'mean_relative_distance', 'attention_to_bos', 'frobenius']\n",
      "  Extract MHA output: True\n",
      "  Need head outputs: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b299b31558b47bfa1c0916231859d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using instruction end token: [/INST]\n",
      "Model loaded: 32 heads, dim=4096\n",
      "Target layers: [16]\n",
      "\n",
      "Extractor initialized:\n",
      "  Target layers: [16]\n",
      "  Num heads: 32\n",
      "  Hidden size: 4096\n",
      "  Stats: 12 types\n",
      "  Expected attention stat features: 384\n",
      "  Expected MHA output features: 4096\n",
      "Saved feature names to attention_feature_names.txt\n",
      "\n",
      "[test split] Extracting attention data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting attention features: 100%|██████████| 2722/2722 [1:05:52<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention stats shape: (21776, 384)\n",
      "MHA output shape: (21776, 4096)\n",
      "\n",
      "attention_stats:\n",
      "  Shape: (21776, 384)\n",
      "  Dtype: float32\n",
      "  Range: [0.0000, 492.5853]\n",
      "  Mean: 11.0324\n",
      "  Has NaN: False\n",
      "\n",
      "mha_output:\n",
      "  Shape: (21776, 4096)\n",
      "  Dtype: float32\n",
      "  Range: [-1.1021, 0.5809]\n",
      "  Mean: -0.0004\n",
      "  Has NaN: False\n",
      "\n",
      "Saved attention_stats to test_attention_stats_layer16.npy\n",
      "Saved mha_output to test_mha_output_layer16.npy\n",
      "\n",
      "[val split] Extracting attention data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting attention features: 100%|██████████| 2722/2722 [1:01:39<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention stats shape: (21775, 384)\n",
      "MHA output shape: (21775, 4096)\n",
      "\n",
      "attention_stats:\n",
      "  Shape: (21775, 384)\n",
      "  Dtype: float32\n",
      "  Range: [0.0000, 492.5765]\n",
      "  Mean: 11.0344\n",
      "  Has NaN: False\n",
      "\n",
      "mha_output:\n",
      "  Shape: (21775, 4096)\n",
      "  Dtype: float32\n",
      "  Range: [-1.1750, 1.3672]\n",
      "  Mean: -0.0004\n",
      "  Has NaN: False\n",
      "\n",
      "Saved attention_stats to val_attention_stats_layer16.npy\n",
      "Saved mha_output to val_mha_output_layer16.npy\n",
      "\n",
      "[train split] Extracting attention data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting attention features: 100%|██████████| 12703/12703 [5:09:27<00:00,  1.46s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention stats shape: (101618, 384)\n",
      "MHA output shape: (101618, 4096)\n",
      "\n",
      "attention_stats:\n",
      "  Shape: (101618, 384)\n",
      "  Dtype: float32\n",
      "  Range: [0.0000, 499.0262]\n",
      "  Mean: 11.0165\n",
      "  Has NaN: False\n",
      "\n",
      "mha_output:\n",
      "  Shape: (101618, 4096)\n",
      "  Dtype: float32\n",
      "  Range: [-1.2734, 1.1875]\n",
      "  Mean: -0.0004\n",
      "  Has NaN: False\n",
      "\n",
      "Saved attention_stats to train_attention_stats_layer16.npy\n",
      "Saved mha_output to train_mha_output_layer16.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from llmscan import AttentionExtractor, AVAILABLE_STATS\n",
    "\n",
    "# List of statistics to compute (top1_mass is redundant with max, so we remove it)\n",
    "STATS_TO_EXCLUDE = [\n",
    "    \"top1_mass\",\n",
    "    \"head_output_norm\",\n",
    "    \"attn_value_correlation\"\n",
    "]\n",
    "STATS_TO_COMPUTE = [\n",
    "    stat for stat in AVAILABLE_STATS.copy() if stat not in STATS_TO_EXCLUDE\n",
    "]\n",
    "\n",
    "# Initialize attention extractor\n",
    "extractor = AttentionExtractor(\n",
    "    model_name=\"mistralai/Ministral-8B-Instruct-2410\",\n",
    "    target_layers=[16],\n",
    "    stats_to_compute=STATS_TO_COMPUTE,\n",
    "    extract_mha_output=True, # Also extract MHA output vectors\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "print(f\"\\nExtractor initialized:\")\n",
    "print(f\"  Target layers: {extractor.target_layers}\")\n",
    "print(f\"  Num heads: {extractor.num_heads}\")\n",
    "print(f\"  Hidden size: {extractor.hidden_size}\")\n",
    "print(f\"  Stats: {len(STATS_TO_COMPUTE)} types\")\n",
    "print(f\"  Expected attention stat features: {len(STATS_TO_COMPUTE) * extractor.num_heads}\")\n",
    "print(f\"  Expected MHA output features: {extractor.hidden_size}\")\n",
    "\n",
    "# Save feature names for reference\n",
    "feature_names = extractor.get_feature_names()\n",
    "with open('attention_feature_names.txt', 'w') as f:\n",
    "    for name in feature_names:\n",
    "        f.write(name + '\\n')\n",
    "print(f\"Saved feature names to attention_feature_names.txt\")\n",
    "\n",
    "# We will now extract attention data for each split\n",
    "for split, data in zip([\"test\", \"val\", \"train\"], [test_data, val_data, train_data]):\n",
    "    print(f\"\\n[{split} split] Extracting attention data...\")\n",
    "    features = extractor.extract(\n",
    "        raw_texts=data,\n",
    "        batch_size=8, #2,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    # Inspect extraction results\n",
    "    for key, arr in features.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        print(f\"  Shape: {arr.shape}\")\n",
    "        print(f\"  Dtype: {arr.dtype}\")\n",
    "        print(f\"  Range: [{arr.min():.4f}, {arr.max():.4f}]\")\n",
    "        print(f\"  Mean: {arr.mean():.4f}\")\n",
    "        print(f\"  Has NaN: {np.isnan(arr).any()}\")\n",
    "\n",
    "    # Save attention statistics\n",
    "    os.makedirs(\"attention_cache16\", exist_ok=True)\n",
    "    if 'attention_stats' in features:\n",
    "        np.save(f'attention_cache16/{split}_attention_stats_layer16.npy', features['attention_stats'])\n",
    "        print(f\"\\nSaved attention_stats to {split}_attention_stats_layer16.npy\")\n",
    "\n",
    "    # Save MHA outputs\n",
    "    if 'mha_output' in features:\n",
    "        np.save(f'attention_cache16/{split}_mha_output_layer16.npy', features['mha_output'])\n",
    "        print(f\"Saved mha_output to {split}_mha_output_layer16.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca0a82-a447-42bc-a2b8-86048c8a3f6e",
   "metadata": {
    "id": "33ca0a82-a447-42bc-a2b8-86048c8a3f6e"
   },
   "source": [
    "### 4. Training separate XGBoost probes on attention stats and MHA output\n",
    "\n",
    "Let's evaluate separately attention statistics and the MHA output by training a XGBoost probe on each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e08701-ef90-4b31-aa96-cbcce4305f4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88e08701-ef90-4b31-aa96-cbcce4305f4d",
    "outputId": "f372a98a-0b88-4246-92e8-83eceb13d59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############################\n",
      "# TRAINING ON ATTENTION_STATS #\n",
      "###############################\n",
      "\n",
      "Loading data...\n",
      "Train: 101618, Val: 21775, Test: 21776\n",
      "Labels aligned: train=101618, val=21775, test=21776\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [09:31:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.61638\tval-logloss:0.61667\n",
      "[10]\ttrain-logloss:0.53636\tval-logloss:0.53879\n",
      "[20]\ttrain-logloss:0.49627\tval-logloss:0.50005\n",
      "[30]\ttrain-logloss:0.47250\tval-logloss:0.47714\n",
      "[40]\ttrain-logloss:0.45583\tval-logloss:0.46151\n",
      "[50]\ttrain-logloss:0.44303\tval-logloss:0.44984\n",
      "[60]\ttrain-logloss:0.43312\tval-logloss:0.44101\n",
      "[70]\ttrain-logloss:0.42506\tval-logloss:0.43410\n",
      "[80]\ttrain-logloss:0.41761\tval-logloss:0.42818\n",
      "[90]\ttrain-logloss:0.41054\tval-logloss:0.42296\n",
      "[100]\ttrain-logloss:0.40438\tval-logloss:0.41879\n",
      "[110]\ttrain-logloss:0.39855\tval-logloss:0.41486\n",
      "[120]\ttrain-logloss:0.39353\tval-logloss:0.41163\n",
      "[130]\ttrain-logloss:0.38888\tval-logloss:0.40857\n",
      "[140]\ttrain-logloss:0.38416\tval-logloss:0.40596\n",
      "[150]\ttrain-logloss:0.38030\tval-logloss:0.40406\n",
      "[160]\ttrain-logloss:0.37717\tval-logloss:0.40212\n",
      "[170]\ttrain-logloss:0.37363\tval-logloss:0.40045\n",
      "[180]\ttrain-logloss:0.37072\tval-logloss:0.39912\n",
      "[190]\ttrain-logloss:0.36772\tval-logloss:0.39800\n",
      "[200]\ttrain-logloss:0.36493\tval-logloss:0.39690\n",
      "[210]\ttrain-logloss:0.36205\tval-logloss:0.39577\n",
      "[220]\ttrain-logloss:0.35977\tval-logloss:0.39492\n",
      "[230]\ttrain-logloss:0.35740\tval-logloss:0.39417\n",
      "[240]\ttrain-logloss:0.35476\tval-logloss:0.39318\n",
      "[250]\ttrain-logloss:0.35227\tval-logloss:0.39239\n",
      "[260]\ttrain-logloss:0.34973\tval-logloss:0.39165\n",
      "[270]\ttrain-logloss:0.34761\tval-logloss:0.39085\n",
      "[280]\ttrain-logloss:0.34577\tval-logloss:0.39022\n",
      "[290]\ttrain-logloss:0.34357\tval-logloss:0.38958\n",
      "[300]\ttrain-logloss:0.34162\tval-logloss:0.38914\n",
      "[310]\ttrain-logloss:0.33944\tval-logloss:0.38853\n",
      "[320]\ttrain-logloss:0.33762\tval-logloss:0.38811\n",
      "[330]\ttrain-logloss:0.33579\tval-logloss:0.38757\n",
      "[340]\ttrain-logloss:0.33386\tval-logloss:0.38715\n",
      "[350]\ttrain-logloss:0.33195\tval-logloss:0.38681\n",
      "[360]\ttrain-logloss:0.33009\tval-logloss:0.38662\n",
      "[370]\ttrain-logloss:0.32824\tval-logloss:0.38635\n",
      "[380]\ttrain-logloss:0.32641\tval-logloss:0.38592\n",
      "[390]\ttrain-logloss:0.32445\tval-logloss:0.38548\n",
      "[400]\ttrain-logloss:0.32260\tval-logloss:0.38525\n",
      "[410]\ttrain-logloss:0.32079\tval-logloss:0.38508\n",
      "[420]\ttrain-logloss:0.31892\tval-logloss:0.38476\n",
      "[430]\ttrain-logloss:0.31715\tval-logloss:0.38436\n",
      "[440]\ttrain-logloss:0.31549\tval-logloss:0.38402\n",
      "[450]\ttrain-logloss:0.31393\tval-logloss:0.38372\n",
      "[460]\ttrain-logloss:0.31232\tval-logloss:0.38350\n",
      "[470]\ttrain-logloss:0.31079\tval-logloss:0.38316\n",
      "[480]\ttrain-logloss:0.30905\tval-logloss:0.38291\n",
      "[490]\ttrain-logloss:0.30758\tval-logloss:0.38267\n",
      "[500]\ttrain-logloss:0.30602\tval-logloss:0.38245\n",
      "[510]\ttrain-logloss:0.30440\tval-logloss:0.38226\n",
      "[520]\ttrain-logloss:0.30275\tval-logloss:0.38194\n",
      "[530]\ttrain-logloss:0.30119\tval-logloss:0.38189\n",
      "[540]\ttrain-logloss:0.29967\tval-logloss:0.38169\n",
      "[550]\ttrain-logloss:0.29805\tval-logloss:0.38159\n",
      "[560]\ttrain-logloss:0.29640\tval-logloss:0.38136\n",
      "[570]\ttrain-logloss:0.29485\tval-logloss:0.38124\n",
      "[580]\ttrain-logloss:0.29360\tval-logloss:0.38112\n",
      "[590]\ttrain-logloss:0.29209\tval-logloss:0.38091\n",
      "[600]\ttrain-logloss:0.29070\tval-logloss:0.38075\n",
      "[610]\ttrain-logloss:0.28940\tval-logloss:0.38072\n",
      "[620]\ttrain-logloss:0.28812\tval-logloss:0.38066\n",
      "[630]\ttrain-logloss:0.28660\tval-logloss:0.38059\n",
      "[640]\ttrain-logloss:0.28516\tval-logloss:0.38053\n",
      "[650]\ttrain-logloss:0.28398\tval-logloss:0.38037\n",
      "[660]\ttrain-logloss:0.28258\tval-logloss:0.38026\n",
      "[670]\ttrain-logloss:0.28138\tval-logloss:0.38025\n",
      "[680]\ttrain-logloss:0.27994\tval-logloss:0.38039\n",
      "[690]\ttrain-logloss:0.27851\tval-logloss:0.38013\n",
      "[700]\ttrain-logloss:0.27723\tval-logloss:0.37995\n",
      "[710]\ttrain-logloss:0.27604\tval-logloss:0.37978\n",
      "[720]\ttrain-logloss:0.27468\tval-logloss:0.37970\n",
      "[730]\ttrain-logloss:0.27330\tval-logloss:0.37955\n",
      "[740]\ttrain-logloss:0.27196\tval-logloss:0.37940\n",
      "[750]\ttrain-logloss:0.27058\tval-logloss:0.37942\n",
      "[760]\ttrain-logloss:0.26931\tval-logloss:0.37936\n",
      "[766]\ttrain-logloss:0.26865\tval-logloss:0.37942\n",
      "\n",
      "Training complete. Best iteration: 746\n",
      "Best validation logloss: 0.3794\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Accuracy:  0.8186\n",
      "Precision: 0.7945\n",
      "Recall:    0.5883\n",
      "F1 Score:  0.6760\n",
      "AUC:       0.8846\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8261    0.9278    0.8740     14769\n",
      "           1     0.7945    0.5883    0.6760      7007\n",
      "\n",
      "    accuracy                         0.8186     21776\n",
      "   macro avg     0.8103    0.7580    0.7750     21776\n",
      "weighted avg     0.8159    0.8186    0.8103     21776\n",
      "\n",
      "============================================================\n",
      "Model saved to hallucination_attention_stats_layer_16.pkl\n",
      "\n",
      "Probe saved!\n",
      "Best threshold: 0.350\n",
      "Precision: 0.668, Recall: 0.748, F1: 0.705\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8732    0.8233    0.8475     14769\n",
      "           1     0.6676    0.7480    0.7055      7007\n",
      "\n",
      "    accuracy                         0.7990     21776\n",
      "   macro avg     0.7704    0.7856    0.7765     21776\n",
      "weighted avg     0.8070    0.7990    0.8018     21776\n",
      "\n",
      "\n",
      "##########################\n",
      "# TRAINING ON MHA_OUTPUT #\n",
      "##########################\n",
      "\n",
      "Loading data...\n",
      "Train: 101618, Val: 21775, Test: 21776\n",
      "Labels aligned: train=101618, val=21775, test=21776\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [09:32:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.61334\tval-logloss:0.61382\n",
      "[10]\ttrain-logloss:0.51849\tval-logloss:0.52274\n",
      "[20]\ttrain-logloss:0.47061\tval-logloss:0.47760\n",
      "[30]\ttrain-logloss:0.44164\tval-logloss:0.45094\n",
      "[40]\ttrain-logloss:0.42087\tval-logloss:0.43252\n",
      "[50]\ttrain-logloss:0.40553\tval-logloss:0.41938\n",
      "[60]\ttrain-logloss:0.39162\tval-logloss:0.40882\n",
      "[70]\ttrain-logloss:0.38084\tval-logloss:0.40151\n",
      "[80]\ttrain-logloss:0.37127\tval-logloss:0.39516\n",
      "[90]\ttrain-logloss:0.36312\tval-logloss:0.39041\n",
      "[100]\ttrain-logloss:0.35613\tval-logloss:0.38654\n",
      "[110]\ttrain-logloss:0.34952\tval-logloss:0.38306\n",
      "[120]\ttrain-logloss:0.34381\tval-logloss:0.38024\n",
      "[130]\ttrain-logloss:0.33835\tval-logloss:0.37779\n",
      "[140]\ttrain-logloss:0.33331\tval-logloss:0.37552\n",
      "[150]\ttrain-logloss:0.32865\tval-logloss:0.37352\n",
      "[160]\ttrain-logloss:0.32435\tval-logloss:0.37194\n",
      "[170]\ttrain-logloss:0.32010\tval-logloss:0.37049\n",
      "[180]\ttrain-logloss:0.31605\tval-logloss:0.36908\n",
      "[190]\ttrain-logloss:0.31267\tval-logloss:0.36794\n",
      "[200]\ttrain-logloss:0.30920\tval-logloss:0.36690\n",
      "[210]\ttrain-logloss:0.30589\tval-logloss:0.36620\n",
      "[220]\ttrain-logloss:0.30262\tval-logloss:0.36521\n",
      "[230]\ttrain-logloss:0.29922\tval-logloss:0.36436\n",
      "[240]\ttrain-logloss:0.29626\tval-logloss:0.36363\n",
      "[250]\ttrain-logloss:0.29307\tval-logloss:0.36296\n",
      "[260]\ttrain-logloss:0.29024\tval-logloss:0.36233\n",
      "[270]\ttrain-logloss:0.28739\tval-logloss:0.36167\n",
      "[280]\ttrain-logloss:0.28451\tval-logloss:0.36108\n",
      "[290]\ttrain-logloss:0.28153\tval-logloss:0.36058\n",
      "[300]\ttrain-logloss:0.27877\tval-logloss:0.35992\n",
      "[310]\ttrain-logloss:0.27630\tval-logloss:0.35956\n",
      "[320]\ttrain-logloss:0.27379\tval-logloss:0.35914\n",
      "[330]\ttrain-logloss:0.27153\tval-logloss:0.35865\n",
      "[340]\ttrain-logloss:0.26910\tval-logloss:0.35822\n",
      "[350]\ttrain-logloss:0.26648\tval-logloss:0.35786\n",
      "[360]\ttrain-logloss:0.26407\tval-logloss:0.35767\n",
      "[370]\ttrain-logloss:0.26173\tval-logloss:0.35728\n",
      "[380]\ttrain-logloss:0.25932\tval-logloss:0.35677\n",
      "[390]\ttrain-logloss:0.25699\tval-logloss:0.35661\n",
      "[400]\ttrain-logloss:0.25464\tval-logloss:0.35637\n",
      "[410]\ttrain-logloss:0.25236\tval-logloss:0.35635\n",
      "[420]\ttrain-logloss:0.25014\tval-logloss:0.35608\n",
      "[430]\ttrain-logloss:0.24818\tval-logloss:0.35587\n",
      "[440]\ttrain-logloss:0.24611\tval-logloss:0.35570\n",
      "[450]\ttrain-logloss:0.24415\tval-logloss:0.35551\n",
      "[460]\ttrain-logloss:0.24216\tval-logloss:0.35537\n",
      "[470]\ttrain-logloss:0.24001\tval-logloss:0.35519\n",
      "[480]\ttrain-logloss:0.23816\tval-logloss:0.35508\n",
      "[490]\ttrain-logloss:0.23612\tval-logloss:0.35485\n",
      "[500]\ttrain-logloss:0.23416\tval-logloss:0.35468\n",
      "[510]\ttrain-logloss:0.23201\tval-logloss:0.35454\n",
      "[520]\ttrain-logloss:0.22998\tval-logloss:0.35445\n",
      "[530]\ttrain-logloss:0.22799\tval-logloss:0.35425\n",
      "[540]\ttrain-logloss:0.22587\tval-logloss:0.35417\n",
      "[550]\ttrain-logloss:0.22391\tval-logloss:0.35421\n",
      "[560]\ttrain-logloss:0.22208\tval-logloss:0.35403\n",
      "[570]\ttrain-logloss:0.22057\tval-logloss:0.35396\n",
      "[580]\ttrain-logloss:0.21891\tval-logloss:0.35392\n",
      "[590]\ttrain-logloss:0.21699\tval-logloss:0.35378\n",
      "[600]\ttrain-logloss:0.21523\tval-logloss:0.35371\n",
      "[610]\ttrain-logloss:0.21358\tval-logloss:0.35360\n",
      "[620]\ttrain-logloss:0.21161\tval-logloss:0.35358\n",
      "[630]\ttrain-logloss:0.20979\tval-logloss:0.35353\n",
      "[640]\ttrain-logloss:0.20815\tval-logloss:0.35338\n",
      "[650]\ttrain-logloss:0.20639\tval-logloss:0.35339\n",
      "[660]\ttrain-logloss:0.20481\tval-logloss:0.35338\n",
      "[666]\ttrain-logloss:0.20385\tval-logloss:0.35336\n",
      "\n",
      "Training complete. Best iteration: 646\n",
      "Best validation logloss: 0.3533\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Accuracy:  0.8338\n",
      "Precision: 0.8137\n",
      "Recall:    0.6269\n",
      "F1 Score:  0.7082\n",
      "AUC:       0.9030\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8404    0.9319    0.8838     14769\n",
      "           1     0.8137    0.6269    0.7082      7007\n",
      "\n",
      "    accuracy                         0.8338     21776\n",
      "   macro avg     0.8270    0.7794    0.7960     21776\n",
      "weighted avg     0.8318    0.8338    0.8273     21776\n",
      "\n",
      "============================================================\n",
      "Model saved to hallucination_mha_output_layer_16.pkl\n",
      "\n",
      "Probe saved!\n",
      "Best threshold: 0.362\n",
      "Precision: 0.710, Recall: 0.750, F1: 0.730\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8782    0.8548    0.8663     14769\n",
      "           1     0.7102    0.7501    0.7296      7007\n",
      "\n",
      "    accuracy                         0.8211     21776\n",
      "   macro avg     0.7942    0.8024    0.7980     21776\n",
      "weighted avg     0.8241    0.8211    0.8223     21776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    classification_report\n",
    ")\n",
    "from llmscan import XGBoostProbe\n",
    "\n",
    "# XGBoost params\n",
    "XGB_PARAMS = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'eval_metric': 'logloss',\n",
    "}\n",
    "\n",
    "for attn in [\"attention_stats\", \"mha_output\"]:\n",
    "    msg = f\"# TRAINING ON {attn.upper()} #\"\n",
    "    print(\"\", \"#\" * len(msg), msg, \"#\" * len(msg), sep=\"\\n\")\n",
    "\n",
    "    # Load cached activations\n",
    "    print(\"\\nLoading data...\")\n",
    "    train_acts = np.load(f\"/workspace/attention_cache16/train_{attn}_layer16.npy\")\n",
    "    val_acts = np.load(f\"/workspace/attention_cache16/val_{attn}_layer16.npy\")\n",
    "    test_acts = np.load(f\"/workspace/attention_cache16/test_{attn}_layer16.npy\")\n",
    "\n",
    "    print(f\"Train: {len(train_acts)}, Val: {len(val_acts)}, Test: {len(test_acts)}\")\n",
    "\n",
    "    # Align labels (trim to match activations)\n",
    "    train_labels_aligned = train_labels[:len(train_acts)]\n",
    "    val_labels_aligned = val_labels[:len(val_acts)]\n",
    "    test_labels_aligned = test_labels[:len(test_acts)]\n",
    "\n",
    "    print(f\"Labels aligned: train={len(train_labels_aligned)}, val={len(val_labels_aligned)}, test={len(test_labels_aligned)}\")\n",
    "\n",
    "    # Train\n",
    "    print(\"\\nTraining XGBoost...\")\n",
    "    probe = XGBoostProbe(xgb_params=XGB_PARAMS)\n",
    "    probe.fit(\n",
    "        train_acts,\n",
    "        train_labels_aligned,\n",
    "        X_val=val_acts,\n",
    "        y_val=val_labels_aligned,\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    metrics = probe.evaluate(test_acts, test_labels_aligned, verbose=True)\n",
    "\n",
    "    # Save probe\n",
    "    probe.save(f\"hallucination_{attn}_layer_16.pkl\")\n",
    "    print(\"\\nProbe saved!\")\n",
    "\n",
    "    # Get probabilities for hallucination class\n",
    "    y_proba = probe.predict_proba(test_acts)[:, 1]\n",
    "\n",
    "    # Get precision-recall curve\n",
    "    precisions, recalls, thresholds = precision_recall_curve(test_labels_aligned, y_proba)\n",
    "\n",
    "    # Compute F1 for each threshold\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "\n",
    "    # Find optimal threshold\n",
    "    best_idx = f1_scores.argmax()\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    print(f\"Best threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Precision: {precisions[best_idx]:.3f}, Recall: {recalls[best_idx]:.3f}, F1: {f1_scores[best_idx]:.3f}\")\n",
    "\n",
    "    # Full report with optimized threshold\n",
    "    y_pred_optimized = (y_proba >= best_threshold).astype(int)\n",
    "    print(\"\\nClassification Report (optimized threshold):\")\n",
    "    print(classification_report(test_labels_aligned, y_pred_optimized, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b6c19-50e5-4e08-b89a-dfe6ef6da265",
   "metadata": {
    "id": "410b6c19-50e5-4e08-b89a-dfe6ef6da265"
   },
   "source": [
    "### 5. Training a XGBoost probe on concatenated attention and activation layers\n",
    "\n",
    "The results above show no significant improvement over our earlier findings. As a next step, we concatenate all features spanning from layer 15's FFN output to layer 16's FFN output, including layer 16's attention statistics and multi-head attention output:\n",
    "\n",
    "```\n",
    "    Layer 15                                 Layer 16\n",
    "{[FFN output]} -> {[Per-head attention statistics] -> [MHA output] -> [FFN output]}\n",
    "```\n",
    "\n",
    "Then, we'll evaluate the effect of feature selection by retaining varying percentages of the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d5e613-e3ad-4bdd-a090-d66483486d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN ===\n",
      "Computing total feature dimension...\n",
      "  /workspace/feature_cache15/train_activations_pooled.pt: 4096 features\n",
      "  /workspace/attention_cache16/train_attention_stats_layer16.npy: 384 features\n",
      "  /workspace/attention_cache16/train_mha_output_layer16.npy: 4096 features\n",
      "  /workspace/feature_cache16/train_activations_pooled.pt: 4096 features\n",
      "Total features: 12672\n",
      "Creating memmap at /workspace/concat_features/train.dat with shape (101618, 12672)...\n",
      "Loading and copying /workspace/feature_cache15/train_activations_pooled.pt...\n",
      "  Copied 4096 features (columns 0 to 4096)\n",
      "Loading and copying /workspace/attention_cache16/train_attention_stats_layer16.npy...\n",
      "  Copied 384 features (columns 4096 to 4480)\n",
      "Loading and copying /workspace/attention_cache16/train_mha_output_layer16.npy...\n",
      "  Copied 4096 features (columns 4480 to 8576)\n",
      "Loading and copying /workspace/feature_cache16/train_activations_pooled.pt...\n",
      "  Copied 4096 features (columns 8576 to 12672)\n",
      "Done.\n",
      "\n",
      "=== VAL ===\n",
      "Computing total feature dimension...\n",
      "  /workspace/feature_cache15/val_activations_pooled.pt: 4096 features\n",
      "  /workspace/attention_cache16/val_attention_stats_layer16.npy: 384 features\n",
      "  /workspace/attention_cache16/val_mha_output_layer16.npy: 4096 features\n",
      "  /workspace/feature_cache16/val_activations_pooled.pt: 4096 features\n",
      "Total features: 12672\n",
      "Creating memmap at /workspace/concat_features/val.dat with shape (21775, 12672)...\n",
      "Loading and copying /workspace/feature_cache15/val_activations_pooled.pt...\n",
      "  Copied 4096 features (columns 0 to 4096)\n",
      "Loading and copying /workspace/attention_cache16/val_attention_stats_layer16.npy...\n",
      "  Copied 384 features (columns 4096 to 4480)\n",
      "Loading and copying /workspace/attention_cache16/val_mha_output_layer16.npy...\n",
      "  Copied 4096 features (columns 4480 to 8576)\n",
      "Loading and copying /workspace/feature_cache16/val_activations_pooled.pt...\n",
      "  Copied 4096 features (columns 8576 to 12672)\n",
      "Done.\n",
      "\n",
      "=== TEST ===\n",
      "Computing total feature dimension...\n",
      "  /workspace/feature_cache15/test_activations_pooled.pt: 4096 features\n",
      "  /workspace/attention_cache16/test_attention_stats_layer16.npy: 384 features\n",
      "  /workspace/attention_cache16/test_mha_output_layer16.npy: 4096 features\n",
      "  /workspace/feature_cache16/test_activations_pooled.pt: 4096 features\n",
      "Total features: 12672\n",
      "Creating memmap at /workspace/concat_features/test.dat with shape (21776, 12672)...\n",
      "Loading and copying /workspace/feature_cache15/test_activations_pooled.pt...\n",
      "  Copied 4096 features (columns 0 to 4096)\n",
      "Loading and copying /workspace/attention_cache16/test_attention_stats_layer16.npy...\n",
      "  Copied 384 features (columns 4096 to 4480)\n",
      "Loading and copying /workspace/attention_cache16/test_mha_output_layer16.npy...\n",
      "  Copied 4096 features (columns 4480 to 8576)\n",
      "Loading and copying /workspace/feature_cache16/test_activations_pooled.pt...\n",
      "  Copied 4096 features (columns 8576 to 12672)\n",
      "Done.\n",
      "\n",
      "Final shapes:\n",
      "  Train: (101618, 12672)\n",
      "  Val:   (21775, 12672)\n",
      "  Test:  (21776, 12672)\n",
      "\n",
      "Labels aligned:\n",
      "  Train: 101618\n",
      "  Val:   21775\n",
      "  Test:  21776\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def load_torch_as_numpy(path):\n",
    "    \"\"\"Load a .pt file and convert to numpy float32.\"\"\"\n",
    "    tensor = torch.load(path, map_location=\"cpu\", weights_only=True)\n",
    "    arr = tensor.float().numpy()\n",
    "    del tensor\n",
    "    return arr\n",
    "\n",
    "def load_numpy(path):\n",
    "    \"\"\"Load a .npy file.\"\"\"\n",
    "    return np.load(path)\n",
    "\n",
    "def build_concat_streaming(output_path, sources, n_samples):\n",
    "    \"\"\"\n",
    "    Build concatenated features by streaming arrays one at a time.\n",
    "    \n",
    "    Args:\n",
    "        output_path: Where to save the memory-mapped output\n",
    "        sources: List of (path, loader_fn) tuples\n",
    "        n_samples: Number of samples to include\n",
    "    \n",
    "    Returns:\n",
    "        np.memmap array of shape (n_samples, total_features)\n",
    "    \"\"\"\n",
    "    # First pass: compute total feature dimension\n",
    "    print(\"Computing total feature dimension...\")\n",
    "    total_dim = 0\n",
    "    dims = []\n",
    "    for path, loader_fn in sources:\n",
    "        arr = loader_fn(path)\n",
    "        dims.append(arr.shape[1])\n",
    "        total_dim += arr.shape[1]\n",
    "        print(f\"  {path}: {arr.shape[1]} features\")\n",
    "        del arr\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"Total features: {total_dim}\")\n",
    "    \n",
    "    # Allocate memory-mapped output\n",
    "    print(f\"Creating memmap at {output_path} with shape ({n_samples}, {total_dim})...\")\n",
    "    out = np.memmap(output_path, dtype=np.float32, mode='w+', shape=(n_samples, total_dim))\n",
    "    \n",
    "    # Second pass: fill the array\n",
    "    col = 0\n",
    "    for i, (path, loader_fn) in enumerate(sources):\n",
    "        print(f\"Loading and copying {path}...\")\n",
    "        arr = loader_fn(path).astype(np.float32, copy=False)\n",
    "        width = arr.shape[1]\n",
    "        out[:, col:col + width] = arr[:n_samples]\n",
    "        out.flush()  # Ensure data is written to disk\n",
    "        col += width\n",
    "        print(f\"  Copied {width} features (columns {col - width} to {col})\")\n",
    "        del arr\n",
    "        gc.collect()\n",
    "    \n",
    "    print(\"Done.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# Define sources for each split\n",
    "train_sources = [\n",
    "    (\"/workspace/feature_cache15/train_activations_pooled.pt\", load_torch_as_numpy),\n",
    "    (\"/workspace/attention_cache16/train_attention_stats_layer16.npy\", load_numpy),\n",
    "    (\"/workspace/attention_cache16/train_mha_output_layer16.npy\", load_numpy),\n",
    "    (\"/workspace/feature_cache16/train_activations_pooled.pt\", load_torch_as_numpy),\n",
    "]\n",
    "\n",
    "val_sources = [\n",
    "    (\"/workspace/feature_cache15/val_activations_pooled.pt\", load_torch_as_numpy),\n",
    "    (\"/workspace/attention_cache16/val_attention_stats_layer16.npy\", load_numpy),\n",
    "    (\"/workspace/attention_cache16/val_mha_output_layer16.npy\", load_numpy),\n",
    "    (\"/workspace/feature_cache16/val_activations_pooled.pt\", load_torch_as_numpy),\n",
    "]\n",
    "\n",
    "test_sources = [\n",
    "    (\"/workspace/feature_cache15/test_activations_pooled.pt\", load_torch_as_numpy),\n",
    "    (\"/workspace/attention_cache16/test_attention_stats_layer16.npy\", load_numpy),\n",
    "    (\"/workspace/attention_cache16/test_mha_output_layer16.npy\", load_numpy),\n",
    "    (\"/workspace/feature_cache16/test_activations_pooled.pt\", load_torch_as_numpy),\n",
    "]\n",
    "\n",
    "# Sample counts\n",
    "n_train = 101618\n",
    "n_val = 21775\n",
    "n_test = 21776\n",
    "\n",
    "# Output directory for memmaps\n",
    "output_dir = Path(\"/workspace/concat_features\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Build concatenated features\n",
    "print(\"\\n=== TRAIN ===\")\n",
    "train_acts = build_concat_streaming(output_dir / \"train.dat\", train_sources, n_train)\n",
    "\n",
    "print(\"\\n=== VAL ===\")\n",
    "val_acts = build_concat_streaming(output_dir / \"val.dat\", val_sources, n_val)\n",
    "\n",
    "print(\"\\n=== TEST ===\")\n",
    "test_acts = build_concat_streaming(output_dir / \"test.dat\", test_sources, n_test)\n",
    "\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  Train: {train_acts.shape}\")\n",
    "print(f\"  Val:   {val_acts.shape}\")\n",
    "print(f\"  Test:  {test_acts.shape}\")\n",
    "\n",
    "# Labels\n",
    "train_labels_aligned = train_labels[:n_train]\n",
    "val_labels_aligned = val_labels[:n_val]\n",
    "test_labels_aligned = test_labels[:n_test]\n",
    "\n",
    "print(f\"\\nLabels aligned:\")\n",
    "print(f\"  Train: {len(train_labels_aligned)}\")\n",
    "print(f\"  Val:   {len(val_labels_aligned)}\")\n",
    "print(f\"  Test:  {len(test_labels_aligned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce889d4b-8bac-4699-91d3-96668c7892c9",
   "metadata": {},
   "source": [
    "Now, let's train a probe on the concatenated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e1056c-0b88-4f65-9270-d6f73e565046",
   "metadata": {
    "id": "a5e1056c-0b88-4f65-9270-d6f73e565046",
    "outputId": "6e49e4ec-9a41-4077-8535-bb2b984a575b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:42:38] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.61317\tval-logloss:0.61355\n",
      "[10]\ttrain-logloss:0.51718\tval-logloss:0.52024\n",
      "[20]\ttrain-logloss:0.46408\tval-logloss:0.46947\n",
      "[30]\ttrain-logloss:0.43264\tval-logloss:0.43997\n",
      "[40]\ttrain-logloss:0.41272\tval-logloss:0.42196\n",
      "[50]\ttrain-logloss:0.39797\tval-logloss:0.40894\n",
      "[60]\ttrain-logloss:0.38507\tval-logloss:0.39868\n",
      "[70]\ttrain-logloss:0.37419\tval-logloss:0.39082\n",
      "[80]\ttrain-logloss:0.36488\tval-logloss:0.38493\n",
      "[90]\ttrain-logloss:0.35645\tval-logloss:0.37970\n",
      "[100]\ttrain-logloss:0.34929\tval-logloss:0.37611\n",
      "[110]\ttrain-logloss:0.34285\tval-logloss:0.37293\n",
      "[120]\ttrain-logloss:0.33677\tval-logloss:0.36991\n",
      "[130]\ttrain-logloss:0.33081\tval-logloss:0.36764\n",
      "[140]\ttrain-logloss:0.32561\tval-logloss:0.36569\n",
      "[150]\ttrain-logloss:0.32098\tval-logloss:0.36396\n",
      "[160]\ttrain-logloss:0.31627\tval-logloss:0.36219\n",
      "[170]\ttrain-logloss:0.31191\tval-logloss:0.36078\n",
      "[180]\ttrain-logloss:0.30786\tval-logloss:0.35946\n",
      "[190]\ttrain-logloss:0.30392\tval-logloss:0.35832\n",
      "[200]\ttrain-logloss:0.30005\tval-logloss:0.35725\n",
      "[210]\ttrain-logloss:0.29623\tval-logloss:0.35646\n",
      "[220]\ttrain-logloss:0.29306\tval-logloss:0.35569\n",
      "[230]\ttrain-logloss:0.28961\tval-logloss:0.35486\n",
      "[240]\ttrain-logloss:0.28625\tval-logloss:0.35405\n",
      "[250]\ttrain-logloss:0.28306\tval-logloss:0.35317\n",
      "[260]\ttrain-logloss:0.28018\tval-logloss:0.35278\n",
      "[270]\ttrain-logloss:0.27731\tval-logloss:0.35216\n",
      "[280]\ttrain-logloss:0.27402\tval-logloss:0.35149\n",
      "[290]\ttrain-logloss:0.27122\tval-logloss:0.35093\n",
      "[300]\ttrain-logloss:0.26843\tval-logloss:0.35035\n",
      "[310]\ttrain-logloss:0.26565\tval-logloss:0.35003\n",
      "[320]\ttrain-logloss:0.26290\tval-logloss:0.34964\n",
      "[330]\ttrain-logloss:0.26034\tval-logloss:0.34910\n",
      "[340]\ttrain-logloss:0.25755\tval-logloss:0.34895\n",
      "[350]\ttrain-logloss:0.25520\tval-logloss:0.34852\n",
      "[360]\ttrain-logloss:0.25261\tval-logloss:0.34811\n",
      "[370]\ttrain-logloss:0.25007\tval-logloss:0.34774\n",
      "[380]\ttrain-logloss:0.24753\tval-logloss:0.34746\n",
      "[390]\ttrain-logloss:0.24517\tval-logloss:0.34733\n",
      "[400]\ttrain-logloss:0.24298\tval-logloss:0.34696\n",
      "[410]\ttrain-logloss:0.24055\tval-logloss:0.34671\n",
      "[420]\ttrain-logloss:0.23813\tval-logloss:0.34653\n",
      "[430]\ttrain-logloss:0.23589\tval-logloss:0.34643\n",
      "[440]\ttrain-logloss:0.23359\tval-logloss:0.34610\n",
      "[450]\ttrain-logloss:0.23157\tval-logloss:0.34572\n",
      "[460]\ttrain-logloss:0.22967\tval-logloss:0.34551\n",
      "[470]\ttrain-logloss:0.22750\tval-logloss:0.34561\n",
      "[480]\ttrain-logloss:0.22528\tval-logloss:0.34550\n",
      "[490]\ttrain-logloss:0.22315\tval-logloss:0.34532\n",
      "[500]\ttrain-logloss:0.22118\tval-logloss:0.34512\n",
      "[510]\ttrain-logloss:0.21909\tval-logloss:0.34487\n",
      "[520]\ttrain-logloss:0.21705\tval-logloss:0.34467\n",
      "[530]\ttrain-logloss:0.21501\tval-logloss:0.34435\n",
      "[540]\ttrain-logloss:0.21294\tval-logloss:0.34412\n",
      "[550]\ttrain-logloss:0.21109\tval-logloss:0.34413\n",
      "[560]\ttrain-logloss:0.20940\tval-logloss:0.34394\n",
      "[570]\ttrain-logloss:0.20783\tval-logloss:0.34385\n",
      "[580]\ttrain-logloss:0.20600\tval-logloss:0.34403\n",
      "[589]\ttrain-logloss:0.20440\tval-logloss:0.34386\n",
      "\n",
      "Training complete. Best iteration: 569\n",
      "Best validation logloss: 0.3438\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Accuracy:  0.8403\n",
      "Precision: 0.8224\n",
      "Recall:    0.6425\n",
      "F1 Score:  0.7214\n",
      "AUC:       0.9091\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8463    0.9342    0.8881     14769\n",
      "           1     0.8224    0.6425    0.7214      7007\n",
      "\n",
      "    accuracy                         0.8403     21776\n",
      "   macro avg     0.8344    0.7883    0.8048     21776\n",
      "weighted avg     0.8386    0.8403    0.8345     21776\n",
      "\n",
      "============================================================\n",
      "Model saved to hallucination_probe_full_layers_15_16.pkl\n",
      "\n",
      "Probe saved!\n",
      "Best threshold: 0.376\n",
      "Precision: 0.735, Recall: 0.754, F1: 0.745\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8820    0.8711    0.8765     14769\n",
      "           1     0.7352    0.7544    0.7447      7007\n",
      "\n",
      "    accuracy                         0.8335     21776\n",
      "   macro avg     0.8086    0.8127    0.8106     21776\n",
      "weighted avg     0.8348    0.8335    0.8341     21776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llmscan import XGBoostProbe\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_PARAMS = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'eval_metric': 'logloss',\n",
    "}\n",
    "\n",
    "# Train\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "probe_full = XGBoostProbe(xgb_params=XGB_PARAMS)\n",
    "probe_full.fit(\n",
    "    train_acts,\n",
    "    train_labels_aligned,\n",
    "    X_val=val_acts,\n",
    "    y_val=val_labels_aligned,\n",
    "    early_stopping_rounds=20,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "metrics = probe_full.evaluate(test_acts, test_labels_aligned, verbose=True)\n",
    "\n",
    "# Save probe\n",
    "probe_full.save(\"hallucination_probe_full_layers_15_16.pkl\")\n",
    "print(\"\\nProbe saved!\")\n",
    "\n",
    "# Get probabilities for hallucination class\n",
    "y_proba = probe_full.predict_proba(test_acts)[:, 1]\n",
    "\n",
    "# Get precision-recall curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(test_labels_aligned, y_proba)\n",
    "\n",
    "# Compute F1 for each threshold\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "\n",
    "# Find optimal threshold\n",
    "best_idx = f1_scores.argmax()\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.3f}\")\n",
    "print(f\"Precision: {precisions[best_idx]:.3f}, Recall: {recalls[best_idx]:.3f}, F1: {f1_scores[best_idx]:.3f}\")\n",
    "\n",
    "# Full report with optimized threshold\n",
    "y_pred_optimized = (y_proba >= best_threshold).astype(int)\n",
    "print(\"\\nClassification Report (optimized threshold):\")\n",
    "print(classification_report(test_labels_aligned, y_pred_optimized, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f5b30-daa3-4f6f-9782-c46b42b766fd",
   "metadata": {
    "id": "860f5b30-daa3-4f6f-9782-c46b42b766fd"
   },
   "source": [
    "### 6. Feature selection experiment\n",
    "\n",
    "Now that we trained the probe on the concatenated dataset, let's select various percentage of most important features and train a probe on each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447df794-af4e-4359-bc93-4573c08ee91f",
   "metadata": {
    "id": "447df794-af4e-4359-bc93-4573c08ee91f",
    "outputId": "6c653f42-92d3-4e01-efc1-49e5266bfc63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "FEATURE SELECTION EXPERIMENT\n",
      "==============================================================\n",
      "\n",
      "Extracting feature importance...\n",
      "\tTotal features: 10775\n",
      "\tFeatures with non-zero importance: 10775\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 500 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 500 features (indices: [9605, 5580, 5156, 1845, 11742]...[9412, 10065, 5672, 9130, 10826])\n",
      "Subset shapes: (101618, 500), (21775, 500), (21776, 500)\n",
      "Training XGBoost on 500 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:43:39] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 649)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8312, Recall=0.7383, F1=0.7379, AUC=0.9069\n",
      "Best threshold: 0.375\n",
      "Precision: 0.725, Recall: 0.752, F1: 0.739\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8803    0.8649    0.8725     14769\n",
      "           1     0.7254    0.7521    0.7385      7007\n",
      "\n",
      "    accuracy                         0.8286     21776\n",
      "   macro avg     0.8028    0.8085    0.8055     21776\n",
      "weighted avg     0.8305    0.8286    0.8294     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 1000 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 1000 features (indices: [9605, 5580, 5156, 1845, 11742]...[7744, 11391, 5340, 9707, 2264])\n",
      "Subset shapes: (101618, 1000), (21775, 1000), (21776, 1000)\n",
      "Training XGBoost on 1000 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:44:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 736)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8282, Recall=0.7418, F1=0.7354, AUC=0.9065\n",
      "Best threshold: 0.370\n",
      "Precision: 0.715, Recall: 0.764, F1: 0.738\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8841    0.8555    0.8696     14769\n",
      "           1     0.7149    0.7637    0.7385      7007\n",
      "\n",
      "    accuracy                         0.8260     21776\n",
      "   macro avg     0.7995    0.8096    0.8040     21776\n",
      "weighted avg     0.8297    0.8260    0.8274     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 1500 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 1500 features (indices: [9605, 5580, 5156, 1845, 11742]...[5424, 12229, 5800, 7393, 659])\n",
      "Subset shapes: (101618, 1500), (21775, 1500), (21776, 1500)\n",
      "Training XGBoost on 1500 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:45:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 649)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8339, Recall=0.7400, F1=0.7415, AUC=0.9089\n",
      "Best threshold: 0.359\n",
      "Precision: 0.718, Recall: 0.771, F1: 0.743\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8875    0.8559    0.8714     14769\n",
      "           1     0.7175    0.7714    0.7435      7007\n",
      "\n",
      "    accuracy                         0.8287     21776\n",
      "   macro avg     0.8025    0.8136    0.8074     21776\n",
      "weighted avg     0.8328    0.8287    0.8303     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 2000 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 2000 features (indices: [9605, 5580, 5156, 1845, 11742]...[1487, 8858, 4144, 5948, 332])\n",
      "Subset shapes: (101618, 2000), (21775, 2000), (21776, 2000)\n",
      "Training XGBoost on 2000 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:46:30] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 607)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8323, Recall=0.7395, F1=0.7395, AUC=0.9086\n",
      "Best threshold: 0.364\n",
      "Precision: 0.718, Recall: 0.770, F1: 0.743\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8871    0.8567    0.8716     14769\n",
      "           1     0.7182    0.7701    0.7433      7007\n",
      "\n",
      "    accuracy                         0.8288     21776\n",
      "   macro avg     0.8026    0.8134    0.8074     21776\n",
      "weighted avg     0.8327    0.8288    0.8303     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 2500 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 2500 features (indices: [9605, 5580, 5156, 1845, 11742]...[9821, 7407, 2989, 11691, 2770])\n",
      "Subset shapes: (101618, 2500), (21775, 2500), (21776, 2500)\n",
      "Training XGBoost on 2500 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:48:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 544)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8325, Recall=0.7413, F1=0.7401, AUC=0.9083\n",
      "Best threshold: 0.362\n",
      "Precision: 0.715, Recall: 0.770, F1: 0.741\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8869    0.8540    0.8701     14769\n",
      "           1     0.7146    0.7704    0.7414      7007\n",
      "\n",
      "    accuracy                         0.8271     21776\n",
      "   macro avg     0.8007    0.8122    0.8058     21776\n",
      "weighted avg     0.8314    0.8271    0.8287     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 3000 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 3000 features (indices: [9605, 5580, 5156, 1845, 11742]...[1051, 7158, 8627, 4334, 10624])\n",
      "Subset shapes: (101618, 3000), (21775, 3000), (21776, 3000)\n",
      "Training XGBoost on 3000 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:50:31] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 572)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8343, Recall=0.7385, F1=0.7415, AUC=0.9098\n",
      "Best threshold: 0.379\n",
      "Precision: 0.738, Recall: 0.750, F1: 0.744\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8803    0.8735    0.8769     14769\n",
      "           1     0.7376    0.7497    0.7436      7007\n",
      "\n",
      "    accuracy                         0.8336     21776\n",
      "   macro avg     0.8089    0.8116    0.8102     21776\n",
      "weighted avg     0.8344    0.8336    0.8340     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 3500 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 3500 features (indices: [9605, 5580, 5156, 1845, 11742]...[6379, 2448, 10906, 6542, 367])\n",
      "Subset shapes: (101618, 3500), (21775, 3500), (21776, 3500)\n",
      "Training XGBoost on 3500 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:53:07] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 696)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8315, Recall=0.7397, F1=0.7386, AUC=0.9087\n",
      "Best threshold: 0.361\n",
      "Precision: 0.717, Recall: 0.769, F1: 0.742\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8865    0.8561    0.8710     14769\n",
      "           1     0.7172    0.7689    0.7421      7007\n",
      "\n",
      "    accuracy                         0.8281     21776\n",
      "   macro avg     0.8018    0.8125    0.8066     21776\n",
      "weighted avg     0.8320    0.8281    0.8296     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 4000 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 4000 features (indices: [9605, 5580, 5156, 1845, 11742]...[1932, 1304, 2990, 2184, 5413])\n",
      "Subset shapes: (101618, 4000), (21775, 4000), (21776, 4000)\n",
      "Training XGBoost on 4000 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [09:56:46] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 599)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8303, Recall=0.7421, F1=0.7378, AUC=0.9077\n",
      "Best threshold: 0.373\n",
      "Precision: 0.720, Recall: 0.761, F1: 0.740\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8836    0.8597    0.8715     14769\n",
      "           1     0.7203    0.7614    0.7403      7007\n",
      "\n",
      "    accuracy                         0.8281     21776\n",
      "   macro avg     0.8020    0.8105    0.8059     21776\n",
      "weighted avg     0.8311    0.8281    0.8293     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 4500 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 4500 features (indices: [9605, 5580, 5156, 1845, 11742]...[6433, 9615, 1116, 3697, 3602])\n",
      "Subset shapes: (101618, 4500), (21775, 4500), (21776, 4500)\n",
      "Training XGBoost on 4500 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [10:00:23] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 507)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8339, Recall=0.7380, F1=0.7409, AUC=0.9085\n",
      "Best threshold: 0.362\n",
      "Precision: 0.718, Recall: 0.768, F1: 0.742\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8860    0.8570    0.8713     14769\n",
      "           1     0.7181    0.7677    0.7420      7007\n",
      "\n",
      "    accuracy                         0.8283     21776\n",
      "   macro avg     0.8020    0.8123    0.8067     21776\n",
      "weighted avg     0.8320    0.8283    0.8297     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 5000 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 5000 features (indices: [9605, 5580, 5156, 1845, 11742]...[2774, 5522, 10693, 3772, 10430])\n",
      "Subset shapes: (101618, 5000), (21775, 5000), (21776, 5000)\n",
      "Training XGBoost on 5000 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [10:04:00] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 667)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8326, Recall=0.7461, F1=0.7415, AUC=0.9088\n",
      "Best threshold: 0.380\n",
      "Precision: 0.730, Recall: 0.756, F1: 0.743\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8823    0.8675    0.8748     14769\n",
      "           1     0.7303    0.7561    0.7430      7007\n",
      "\n",
      "    accuracy                         0.8316     21776\n",
      "   macro avg     0.8063    0.8118    0.8089     21776\n",
      "weighted avg     0.8334    0.8316    0.8324     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 5500 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 5500 features (indices: [9605, 5580, 5156, 1845, 11742]...[11186, 12516, 8274, 5801, 1542])\n",
      "Subset shapes: (101618, 5500), (21775, 5500), (21776, 5500)\n",
      "Training XGBoost on 5500 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [10:09:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 542)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8330, Recall=0.7457, F1=0.7419, AUC=0.9081\n",
      "Best threshold: 0.364\n",
      "Precision: 0.716, Recall: 0.773, F1: 0.743\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8882    0.8544    0.8709     14769\n",
      "           1     0.7158    0.7732    0.7434      7007\n",
      "\n",
      "    accuracy                         0.8283     21776\n",
      "   macro avg     0.8020    0.8138    0.8072     21776\n",
      "weighted avg     0.8327    0.8283    0.8299     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "EXPERIMENT: Top 6000 features\n",
      "==============================================================\n",
      "\n",
      "Selected top 6000 features (indices: [9605, 5580, 5156, 1845, 11742]...[12351, 8197, 9071, 1501, 1593])\n",
      "Subset shapes: (101618, 6000), (21775, 6000), (21776, 6000)\n",
      "Training XGBoost on 6000 selected features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [10:18:11] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining complete (best iteration: 432)\n",
      "Evaluating...\n",
      "  Results: Acc=0.8312, Recall=0.7428, F1=0.7391, AUC=0.9076\n",
      "Best threshold: 0.378\n",
      "Precision: 0.726, Recall: 0.755, F1: 0.740\n",
      "\n",
      "Classification Report (optimized threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8814    0.8651    0.8732     14769\n",
      "           1     0.7263    0.7545    0.7402      7007\n",
      "\n",
      "    accuracy                         0.8295     21776\n",
      "   macro avg     0.8038    0.8098    0.8067     21776\n",
      "weighted avg     0.8315    0.8295    0.8304     21776\n",
      "\n",
      "\n",
      "==============================================================\n",
      "FEATURE SELECTION RESULTS COMPARISON\n",
      "==============================================================\n",
      "\n",
      "Features     Accuracy   Precision  Recall     F1         AUC       \n",
      "--------------------------------------------------------------\n",
      "500          0.8312     0.7375     0.7383     0.7379     0.9069    \n",
      "1000         0.8282     0.7290     0.7418     0.7354     0.9065    \n",
      "1500         0.8339     0.7429     0.7400     0.7415     0.9089    \n",
      "2000         0.8323     0.7394     0.7395     0.7395     0.9086    \n",
      "2500         0.8325     0.7389     0.7413     0.7401     0.9083    \n",
      "3000         0.8343     0.7445     0.7385     0.7415     0.9098    \n",
      "3500         0.8315     0.7375     0.7397     0.7386     0.9087    \n",
      "4000         0.8303     0.7335     0.7421     0.7378     0.9077    \n",
      "4500         0.8339     0.7439     0.7380     0.7409     0.9085    \n",
      "5000         0.8326     0.7369     0.7461     0.7415     0.9088    \n",
      "5500         0.8330     0.7381     0.7457     0.7419     0.9081    \n",
      "6000         0.8312     0.7354     0.7428     0.7391     0.9076    \n",
      "\n",
      "==============================================================\n",
      "BEST MODELS\n",
      "==============================================================\n",
      "\n",
      "Best F1: 5500 features\n",
      "  Accuracy: 0.8330\n",
      "  Recall:   0.7457\n",
      "  F1:       0.7419\n",
      "  AUC:      0.9081\n",
      "\n",
      "Best AUC: 3000 features\n",
      "  Accuracy: 0.8343\n",
      "  Recall:   0.7385\n",
      "  F1:       0.7415\n",
      "  AUC:      0.9098\n",
      "\n",
      "==============================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "==============================================================\n",
      "\n",
      "In top 5500 features:\n",
      "\tActivation layer 15 features: 1744 (31.7%)\n",
      "\tAttention statistics layer 16 features: 159 (2.9%)\n",
      "\tMulti-Head Attention output layer 16 features: 1840 (33.5%)\n",
      "\tActivation layer 16 features:  1757 (31.9%)\n",
      "\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from llmscan import XGBoostProbe\n",
    "\n",
    "print(\"=\"*62)\n",
    "print(\"FEATURE SELECTION EXPERIMENT\")\n",
    "print(\"=\"*62)\n",
    "\n",
    "# Set feature selection parameters (from 500 to 6000 with a 500 iteration step)\n",
    "MIN_FEATURES = 500\n",
    "MAX_FEATURES = 6000\n",
    "ITERATION_STEP = 500\n",
    "\n",
    "# Extract feature importance\n",
    "print(\"\\nExtracting feature importance...\")\n",
    "feature_importance = probe_full.get_feature_importance(\n",
    "    importance_type='gain',\n",
    "    top_k=None\n",
    ")\n",
    "print(f\"\\tTotal features: {len(feature_importance)}\")\n",
    "print(f\"\\tFeatures with non-zero importance: {len([v for v in feature_importance.values() if v > 0])}\")\n",
    "\n",
    "# Initialize list to store metrics\n",
    "results = []\n",
    "\n",
    "# Iterating over various feature numbers\n",
    "for top_k in range(MIN_FEATURES, MAX_FEATURES+1, ITERATION_STEP):\n",
    "    print(\"\\n\" + \"=\"*62)\n",
    "    print(f\"EXPERIMENT: Top {top_k} features\")\n",
    "    print(\"=\"*62)\n",
    "\n",
    "    # Get top-k most important feature indices\n",
    "    top_features = sorted(\n",
    "        feature_importance.items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:top_k]\n",
    "    top_indices = [idx for idx, _ in top_features]\n",
    "\n",
    "    print(f\"\\nSelected top {top_k} features (indices: {top_indices[:5]}...{top_indices[-5:]})\")\n",
    "\n",
    "    # Subset the data\n",
    "    train_acts_subset = train_acts[:, top_indices]\n",
    "    val_acts_subset = val_acts[:, top_indices]\n",
    "    test_acts_subset = test_acts[:, top_indices]\n",
    "\n",
    "    print(f\"Subset shapes: {train_acts_subset.shape}, {val_acts_subset.shape}, {test_acts_subset.shape}\")\n",
    "\n",
    "    # Train new XGBoost on selected features\n",
    "    print(f\"Training XGBoost on {top_k} selected features...\")\n",
    "\n",
    "    XGB_PARAMS = {\n",
    "        'n_estimators': 1000,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'tree_method': 'hist',\n",
    "        'eval_metric': 'logloss',\n",
    "    }\n",
    "\n",
    "    probe_subset = XGBoostProbe(xgb_params=XGB_PARAMS)\n",
    "    probe_subset.fit(\n",
    "        train_acts_subset,\n",
    "        train_labels_aligned,\n",
    "        X_val=val_acts_subset,\n",
    "        y_val=val_labels_aligned,\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\tTraining complete (best iteration: {probe_subset.model.best_iteration})\")\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"Evaluating...\")\n",
    "    metrics = probe_subset.evaluate(\n",
    "        test_acts_subset,\n",
    "        test_labels_aligned,\n",
    "        threshold=0.388,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        'top_k': top_k,\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'f1': metrics['f1'],\n",
    "        'auc': metrics['auc']\n",
    "    })\n",
    "\n",
    "    print(f\"  Results: Acc={metrics['accuracy']:.4f}, Recall={metrics['recall']:.4f}, \"\n",
    "          f\"F1={metrics['f1']:.4f}, AUC={metrics['auc']:.4f}\")\n",
    "\n",
    "    # Get probabilities for hallucination class\n",
    "    y_proba = probe_subset.predict_proba(test_acts_subset)[:, 1]\n",
    "    \n",
    "    # Get precision-recall curve\n",
    "    precisions, recalls, thresholds = precision_recall_curve(test_labels_aligned, y_proba)\n",
    "    \n",
    "    # Compute F1 for each threshold\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    best_idx = f1_scores.argmax()\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    \n",
    "    print(f\"Best threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Precision: {precisions[best_idx]:.3f}, Recall: {recalls[best_idx]:.3f}, F1: {f1_scores[best_idx]:.3f}\")\n",
    "    \n",
    "    # Full report with optimized threshold\n",
    "    y_pred_optimized = (y_proba >= best_threshold).astype(int)\n",
    "    print(\"\\nClassification Report (optimized threshold):\")\n",
    "    print(classification_report(test_labels_aligned, y_pred_optimized, digits=4))\n",
    "\n",
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*62)\n",
    "print(\"FEATURE SELECTION RESULTS COMPARISON\")\n",
    "print(\"=\"*62)\n",
    "\n",
    "print(\"\\n{:<12} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\n",
    "    \"Features\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"\n",
    "))\n",
    "print(\"-\" * 62)\n",
    "\n",
    "for r in results:\n",
    "    print(\"{:<12} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
    "        r['top_k'],\n",
    "        r['accuracy'],\n",
    "        r['precision'],\n",
    "        r['recall'],\n",
    "        r['f1'],\n",
    "        r['auc']\n",
    "    ))\n",
    "\n",
    "# Find best\n",
    "best_f1 = max(results, key=lambda x: x['f1'])\n",
    "best_auc = max(results, key=lambda x: x['auc'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*62)\n",
    "print(\"BEST MODELS\")\n",
    "print(\"=\"*62)\n",
    "\n",
    "print(f\"\\nBest F1: {best_f1['top_k']} features\")\n",
    "print(f\"  Accuracy: {best_f1['accuracy']:.4f}\")\n",
    "print(f\"  Recall:   {best_f1['recall']:.4f}\")\n",
    "print(f\"  F1:       {best_f1['f1']:.4f}\")\n",
    "print(f\"  AUC:      {best_f1['auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest AUC: {best_auc['top_k']} features\")\n",
    "print(f\"  Accuracy: {best_auc['accuracy']:.4f}\")\n",
    "print(f\"  Recall:   {best_auc['recall']:.4f}\")\n",
    "print(f\"  F1:       {best_auc['f1']:.4f}\")\n",
    "print(f\"  AUC:      {best_auc['auc']:.4f}\")\n",
    "\n",
    "# Analyze layer contribution\n",
    "print(\"\\n\" + \"=\"*62)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*62)\n",
    "\n",
    "# Features for activation layer 15, attention summary, MHA output and activation layer 16 have length 406, 384, 4096, 4096\n",
    "features_15 = [idx for idx in top_indices[:best_f1['top_k']] if idx < 4096]\n",
    "attn_16 = [idx for idx in top_indices[:best_f1['top_k']] if idx >= 4096 and idx < 4480] # 4480 = 4096 + 384\n",
    "mha_16 = [idx for idx in top_indices[:best_f1['top_k']] if idx >= 4480 and idx < 8576] # 8576 = 4480 + 4096\n",
    "features_16 = [idx for idx in top_indices[:best_f1['top_k']] if idx >= 8576]\n",
    "\n",
    "print(f\"\\nIn top {best_f1['top_k']} features:\")\n",
    "print(f\"\\tActivation layer 15 features: {len(features_15)} ({len(features_15)/best_f1['top_k']*100:.1f}%)\")\n",
    "print(f\"\\tAttention statistics layer 16 features: {len(attn_16)} ({len(attn_16)/best_f1['top_k']*100:.1f}%)\")\n",
    "print(f\"\\tMulti-Head Attention output layer 16 features: {len(mha_16)} ({len(mha_16)/best_f1['top_k']*100:.1f}%)\")\n",
    "print(f\"\\tActivation layer 16 features:  {len(features_16)} ({len(features_16)/best_f1['top_k']*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87ef4c-e1d0-4743-b021-62f332e31507",
   "metadata": {},
   "source": [
    "### 7. Conclusion\n",
    "\n",
    "While performance showed marginal improvement on the concatenated dataset, diminishing returns persist. Feature selection proved ineffective, suggesting that dimensionality is not the limiting factor. Overall, results plateau at approximately 84% accuracy, 91% AUC, and 75% F1 score (with precision and recall exhibiting comparable values).\n",
    "\n",
    "These findings corroborate our earlier observations:\n",
    "- Hallucination-related signals are present and extractable from the model's internal representations.\n",
    "- These signals are not distributed across layers but can be retrieved from a single layer.\n",
    "\n",
    "The incorporation of multiple layers and attention-specific features yielded no significant improvement, with results plateauing consistently.\n",
    "\n",
    "Although not presented in this notebook series, we evaluated various pooling strategies (max-pooling, attention-weighted pooling, mean/max concatenation) and alternative probes (random forests, logistic regression, neural probes). Mean-pooling consistently outperformed all other pooling approaches, and XGBoost similarly outperformed all alternative probes. We also experimented with probe ensembling across layers and PCA decomposition, both of which yielded marginally inferior results, the former likely due to the concentrated rather than distributed nature of the hallucination signal.\n",
    "\n",
    "Several hypotheses may account for the observed performance ceiling:\n",
    "- *Fundamental limitations:* Hallucination-related signals may be only partially encoded in the model's internal representations, or the encoded information may diverge from the standard academic conceptualisation of hallucination.\n",
    "- *Dataset quality:* A non-negligible false positive/false negative rate in the dataset may introduce noise that no probe, however sophisticated, can overcome.\n",
    "- *Pooling artifacts:* Mean-pooling may attenuate per-token signals, resulting in information loss.\n",
    "\n",
    "A promising avenue for future work would be to retain raw, per-token activations - for instance, from layer 16 alone - and train a transformer-based probe. However, this approach would conflict with our core objective: a lightweight method enabling fast, real-time inference at virtually no additional computational cost. Nevertheless, from a purely research perspective, success with such an approach would demonstrate that hallucination signals are present and retrievable with high precision and recall from the model's internal representations. In other words, it would suggest that the model \"knows\" - whether explicitly or implicitly - when it is hallucinating, a finding with potential implications for future LLM development.\n",
    "\n",
    "That said, the most prudent next step appears to be retraining the XGBoost probe on the single best-performing layer using a carefully curated, high-quality dataset. The dataset employed in this study was generated using relatively sophisticated instructions; however, due to budget constraints, no majority voting mechanism was implemented, nor was human annotation performed. Consequently, the presence of a non-negligible proportion of mislabelled examples cannot be ruled out."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0083a959621c4d708460522cee4c2f20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_13b0d52645834245879187046d6fd8e4",
       "placeholder": "​",
       "style": "IPY_MODEL_976bd147ff38479ca49b078ad4db6dca",
       "value": "Generating test split: 100%"
      }
     },
     "0452669fae8242b298b8d880028098b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_45ed12a939af4988a525a18ff3e2f616",
       "placeholder": "​",
       "style": "IPY_MODEL_2419c406429345d6b664c681cf61cd9d",
       "value": "Generating train split: 100%"
      }
     },
     "0acab963daac41db9bd9779a7098b084": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3a7d585a68f4e1aa8277a12647b25e3",
       "max": 16807817,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83cc4ed651274e27b9015386c2b4d0dd",
       "value": 16807817
      }
     },
     "10b74c33e72240448d47544635a144bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1328b0f8dc204c0e80c3eb2529f07a6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13b0d52645834245879187046d6fd8e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1bbb40ba5bc84a6aba4d713dfea879c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1e296dd4ba2d47038b537ce23ce1e2d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f60bc4dd0aa4f91a93894ac0b097081",
       "placeholder": "​",
       "style": "IPY_MODEL_e66917517e8744acbddff69977fabc80",
       "value": "data/validation-00000-of-00001.parquet: 100%"
      }
     },
     "1e357cf6c2704d78845824c672480807": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f3748df983d4cde9106b37a9d96c635": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1e357cf6c2704d78845824c672480807",
       "max": 16739557,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d6bfd3ea72ae4d989b8e09f895d24d27",
       "value": 16739557
      }
     },
     "2221751de794442f96a67ffab42600d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7be8dff60be34777acee415b27750355",
       "placeholder": "​",
       "style": "IPY_MODEL_52d51718570d42d7a9e354a7419e02da",
       "value": "data/test-00000-of-00001.parquet: 100%"
      }
     },
     "2419c406429345d6b664c681cf61cd9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "268a5142dc4b4d49ad71ac12697d6b4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b51f9b680a254c9e9aa0142185b99187",
        "IPY_MODEL_7d99075f61984ebcaac554325e70c673",
        "IPY_MODEL_f18967fe7d264f59881969d0960001fc"
       ],
       "layout": "IPY_MODEL_1328b0f8dc204c0e80c3eb2529f07a6a"
      }
     },
     "2c24017b536e45aa884931a2772c765a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2de6eda7d4d24143b31286f88c26a1ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "34b95ce1a9574f07b932d4881a10c092": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d683148619be493da43c6b0f41a356ab",
        "IPY_MODEL_ec190b154d6c4d318190846bf09f6967",
        "IPY_MODEL_ceccb80ddc0d4cf39bb6a25ec241111d"
       ],
       "layout": "IPY_MODEL_eef41e96476f4b0bad7006b343db7d90"
      }
     },
     "36a9599d8e6048f9b2f3e833d996da15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "36f5b44b9f5348f49f06237f7cb76b04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38bfaf26ea624a0fab7ef5b963e714b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "39886c30652842eba357df14b00a294c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b3b7ea3c8674fdbbdbc78c34a071956",
       "placeholder": "​",
       "style": "IPY_MODEL_b22abc79b9dc43b3b6887a808831b2fe",
       "value": " 21776/21776 [00:00&lt;00:00, 164454.67 examples/s]"
      }
     },
     "3aca7f7a83734ceda3774b0646358cf0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4133921f995f4cc58da4698148864024": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4373fab6488b438c8ac71a4df9135a5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "45ed12a939af4988a525a18ff3e2f616": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ec26ff17e574164a46e1aa60461400e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52d51718570d42d7a9e354a7419e02da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5c0e015f35b747048ea983c33466a2e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f60bc4dd0aa4f91a93894ac0b097081": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b3b7ea3c8674fdbbdbc78c34a071956": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "710b487e403947d0a194f054f615d65d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0083a959621c4d708460522cee4c2f20",
        "IPY_MODEL_aae39a88bd144458a391de1ebe69a948",
        "IPY_MODEL_39886c30652842eba357df14b00a294c"
       ],
       "layout": "IPY_MODEL_ee18ecf27739433091224048aef7d07e"
      }
     },
     "7782fba325214679abd9ed7a032d3adc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "78091de8c9ff498db284b55a7fe5fe71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79c5ec9874134743b378f9e853ce7a28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_36f5b44b9f5348f49f06237f7cb76b04",
       "placeholder": "​",
       "style": "IPY_MODEL_2de6eda7d4d24143b31286f88c26a1ec",
       "value": "README.md: 100%"
      }
     },
     "7be8dff60be34777acee415b27750355": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d99075f61984ebcaac554325e70c673": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_948c961115ee494ba20fe80368301126",
       "max": 21775,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c754abbfa29043708b0a2e2333396697",
       "value": 21775
      }
     },
     "83cc4ed651274e27b9015386c2b4d0dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8a3d8813321941709be70726461afe0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e4cf79bf89c479f8b57dd4d77dc1e0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8f1c5006c2564151a289266dcbf53c72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "948c961115ee494ba20fe80368301126": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9674ecbcaff548e3810864b953199776": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "976bd147ff38479ca49b078ad4db6dca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a16b45ebe55047d29366829487cb0708": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a540eba5921c4af5b984bbdf70833724": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7eaceee911f481da589a1595495c463": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a82dc08c07c948d5a5052cd5045121e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_79c5ec9874134743b378f9e853ce7a28",
        "IPY_MODEL_f4c1e92080cb4d86b7d85b39f4f228fe",
        "IPY_MODEL_ed5c579bab0f445bbad1fe66597d5dfc"
       ],
       "layout": "IPY_MODEL_10b74c33e72240448d47544635a144bb"
      }
     },
     "aa056af3805642fb8af20ba9c9429b46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a540eba5921c4af5b984bbdf70833724",
       "placeholder": "​",
       "style": "IPY_MODEL_9674ecbcaff548e3810864b953199776",
       "value": " 16.8M/16.8M [00:01&lt;00:00, 16.2MB/s]"
      }
     },
     "aae39a88bd144458a391de1ebe69a948": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f635a6946ec54154a563d38a6c11924f",
       "max": 21776,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_36a9599d8e6048f9b2f3e833d996da15",
       "value": 21776
      }
     },
     "aeb7e90c064e49c4bb2f2a14a84b59fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed0097519ece44409defee81c285d1b8",
       "placeholder": "​",
       "style": "IPY_MODEL_1bbb40ba5bc84a6aba4d713dfea879c2",
       "value": " 16.7M/16.7M [00:01&lt;00:00, 13.6MB/s]"
      }
     },
     "aff3c0dab3014c40871e3b8746e4e2c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0452669fae8242b298b8d880028098b4",
        "IPY_MODEL_d8cc9e95ba774ae489175535bfc4de7b",
        "IPY_MODEL_f5bfe3bc46ce4e7eb3ce3126041e1e84"
       ],
       "layout": "IPY_MODEL_e04a6c11769d4562b4db0b027c39fd04"
      }
     },
     "b22abc79b9dc43b3b6887a808831b2fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b51f9b680a254c9e9aa0142185b99187": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a3d8813321941709be70726461afe0f",
       "placeholder": "​",
       "style": "IPY_MODEL_eb1a302ddb7b42229216c7bdbbceed96",
       "value": "Generating validation split: 100%"
      }
     },
     "c754abbfa29043708b0a2e2333396697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "caa75872b0d64351a72afe3085672a15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce90834f883446718455b635a58d1a73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2221751de794442f96a67ffab42600d7",
        "IPY_MODEL_0acab963daac41db9bd9779a7098b084",
        "IPY_MODEL_aa056af3805642fb8af20ba9c9429b46"
       ],
       "layout": "IPY_MODEL_4ec26ff17e574164a46e1aa60461400e"
      }
     },
     "ceccb80ddc0d4cf39bb6a25ec241111d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d8f6a863ec20497586e077b694b9e78a",
       "placeholder": "​",
       "style": "IPY_MODEL_4373fab6488b438c8ac71a4df9135a5f",
       "value": " 78.7M/78.7M [00:02&lt;00:00, 34.7MB/s]"
      }
     },
     "d2825b07820f478b8bcda4a6ac82cc57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d3a7d585a68f4e1aa8277a12647b25e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d683148619be493da43c6b0f41a356ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f1c5006c2564151a289266dcbf53c72",
       "placeholder": "​",
       "style": "IPY_MODEL_4133921f995f4cc58da4698148864024",
       "value": "data/train-00000-of-00001.parquet: 100%"
      }
     },
     "d6bfd3ea72ae4d989b8e09f895d24d27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d8cc9e95ba774ae489175535bfc4de7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d2825b07820f478b8bcda4a6ac82cc57",
       "max": 101618,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2c24017b536e45aa884931a2772c765a",
       "value": 101618
      }
     },
     "d8f6a863ec20497586e077b694b9e78a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de15348757074e3eae0b2a239316e378": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e04a6c11769d4562b4db0b027c39fd04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e66917517e8744acbddff69977fabc80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eb1a302ddb7b42229216c7bdbbceed96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ec190b154d6c4d318190846bf09f6967": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed1806338c344271be3a0eeecf67c319",
       "max": 78663960,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_38bfaf26ea624a0fab7ef5b963e714b7",
       "value": 78663960
      }
     },
     "ecf05abeb8914aba820fcf25e37682d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1e296dd4ba2d47038b537ce23ce1e2d6",
        "IPY_MODEL_1f3748df983d4cde9106b37a9d96c635",
        "IPY_MODEL_aeb7e90c064e49c4bb2f2a14a84b59fe"
       ],
       "layout": "IPY_MODEL_78091de8c9ff498db284b55a7fe5fe71"
      }
     },
     "ed0097519ece44409defee81c285d1b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed1806338c344271be3a0eeecf67c319": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed5c579bab0f445bbad1fe66597d5dfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de15348757074e3eae0b2a239316e378",
       "placeholder": "​",
       "style": "IPY_MODEL_a16b45ebe55047d29366829487cb0708",
       "value": " 58.5k/58.5k [00:00&lt;00:00, 3.40MB/s]"
      }
     },
     "ee18ecf27739433091224048aef7d07e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eef41e96476f4b0bad7006b343db7d90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f18967fe7d264f59881969d0960001fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5c0e015f35b747048ea983c33466a2e8",
       "placeholder": "​",
       "style": "IPY_MODEL_a7eaceee911f481da589a1595495c463",
       "value": " 21775/21775 [00:00&lt;00:00, 133826.51 examples/s]"
      }
     },
     "f4c1e92080cb4d86b7d85b39f4f228fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_caa75872b0d64351a72afe3085672a15",
       "max": 58522,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8e4cf79bf89c479f8b57dd4d77dc1e0c",
       "value": 58522
      }
     },
     "f5bfe3bc46ce4e7eb3ce3126041e1e84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3aca7f7a83734ceda3774b0646358cf0",
       "placeholder": "​",
       "style": "IPY_MODEL_7782fba325214679abd9ed7a032d3adc",
       "value": " 101618/101618 [00:00&lt;00:00, 106017.31 examples/s]"
      }
     },
     "f635a6946ec54154a563d38a6c11924f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
